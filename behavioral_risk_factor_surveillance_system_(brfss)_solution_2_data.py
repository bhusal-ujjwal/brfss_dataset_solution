# -*- coding: utf-8 -*-
"""Behavioral Risk Factor Surveillance System (BRFSS)_solution_2 data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K0cSgO0lsyXvJPhLDCWAZsNsIAdgh5Ud
"""

# Upload csv file to colab for using it
import pandas as pd
from google.colab import files
upload_file = files.upload()

# use the uploaded file in colab
import io
import numpy as np
import matplotlib.pyplot as plt
assessment3 = pd.read_csv("ITEC610_assessment3_data.csv")
assessment3.head()

# view the details of the dataset to check if data contains null values
assessment3.info()

# Drop the column unnamed since it is just the serial number for the total data and is not relevant for the further steps
assessment3.drop(columns=['Unnamed: 0'], inplace=True)

# again view data to check the changes
assessment3.info()

#Now after removing the unnamed column view descriptive information of the data for preprocessing
assessment3.describe()

# After looking over the descriptive statistics table we find that replacing median of each column might be best option for filling over null values
columns_to_fill = ['age', 'weight2', 'wtyrago', 'wtkg2', 'htm3']
for column in columns_to_fill:
    assessment3[column] = assessment3[column].fillna(assessment3[column].median())

#Now after preprocessing view the changes
assessment3.info()



# Task 1

# summary statistics calculation
summary_statistics = {
    col: {
        'mean': assessment3[col].mean(),
        'median': assessment3[col].median(),
        'std': assessment3[col].std(),
        '25 perc': assessment3[col].quantile(0.25),
        '75 perc': assessment3[col].quantile(0.75),
        'min': assessment3[col].min(),
        'max': assessment3[col].max(),
    } for col in ['weight2', 'wtyrago', 'htm3']
}

# plotting the required summary statistics calculation, renaming them
columns = {'weight2': 'Current weight', 'wtyrago': 'Weight a year ago', 'htm3': 'Height'}
x_positions = np.arange(len(columns))
width = 0.2

# define the markers, colors, and positions for each statistic
stats_info = {
    'max': {'marker': 'v', 'color': 'black', 'offset': -2*width},
    'min': {'marker': '^', 'color': 'black', 'offset': -width},
    'mean': {'marker': '+', 'color': 'blue', 'offset': 0},
    'median': {'marker': 'x', 'color': 'blue', 'offset': width},
    'mean+std': {'marker': 'v', 'color': 'green', 'offset': 2*width},
    'mean-std': {'marker': '^', 'color': 'green', 'offset': 3*width},
    '75 perc': {'marker': 'v', 'color': 'red', 'offset': 4*width},
    '25 perc': {'marker': '^', 'color': 'red', 'offset': 5*width},
}

# plotting the points, adding labels, legend, titles and finally visualizing the summary statistics graph
[plt.scatter(x_positions + info['offset'],
[summary_statistics[col][stat] if '+' not in stat and '-' not in stat else summary_statistics[col]['mean'] + summary_statistics[col]['std'] if '+' in stat else summary_statistics[col]
['mean'] - summary_statistics[col]['std'] for col in columns], marker=info['marker'], color=info['color'], label=stat) for stat, info in stats_info.items()]

plt.xticks(x_positions, list(columns.values()))
plt.ylabel('Values')
plt.title('Summary Statistics Graph')
plt.legend(loc='best')
plt.show()



# Task 2

#define weight_change and calculate correlations with weight change
assessment3['weight_change'] = assessment3['weight2'] - assessment3['wtyrago']
correlations = assessment3[['weight_change', 'weight2', 'wtyrago', 'age']].corr()
print(correlations['weight_change'])

# determine which variable is most correlated with weight_change
most_correlated = correlations['weight_change'].drop('weight_change').idxmax()
print(f"The variable most correlated with weight_change is {most_correlated}")

# plot scatter plots
for col in ['weight2', 'wtyrago', 'age']:
    plt.figure(figsize=(8, 6))
    plt.scatter(assessment3[col], assessment3['weight_change'])
    plt.xlabel(col)
    plt.ylabel('Weight Change')
    plt.title(f'Scatter plot of Weight Change vs {col}')
    plt.show()



# Task 3

# linear regression model using scikit-learn, for training it on given house sizes and prices and predicts the price of a 2500 sqft house.
from sklearn.linear_model import LinearRegression
house_sizes = [[1500], [2000], [2500], [3000], [3500]]
house_prices = [250000, 300000, 330000, 360000, 390000]
model = LinearRegression()
model.fit(house_sizes, house_prices)
predicted_price = model.predict([[2500]])
print(f"For 2500 sqft area predicted house price is: {predicted_price[0]}")

